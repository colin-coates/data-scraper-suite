# Copyright (c) 2024 Mountain Jewels Intelligence. All rights reserved.
#
# This software is proprietary and confidential. Unauthorized copying,
# modification, distribution, or use is strictly prohibited.

"""
WAF Sentinel for MJ Data Scraper Suite

Detects and assesses Web Application Firewall protections, bot detection systems,
and anti-scraping measures on target websites.
"""

import asyncio
import logging
import re
from typing import Dict, Any, List, Optional, Tuple, Set
from datetime import datetime
from urllib.parse import urlparse, urljoin

try:
    import aiohttp
    AIOHTTP_AVAILABLE = True
except ImportError:
    AIOHTTP_AVAILABLE = False

from .base import BaseSentinel, SentinelReport

logger = logging.getLogger(__name__)


class WafSentinel(BaseSentinel):
    """
    Monitors websites for Web Application Firewall protections and anti-scraping measures.

    Analyzes HTTP responses, headers, and content to detect WAF systems,
    bot detection, rate limiting, and other anti-scraping protections.
    """

    name = "waf_sentinel"

    def __init__(self):
        # WAF detection patterns and signatures
        self.waf_signatures = {
            "cloudflare": {
                "headers": ["cf-ray", "cf-cache-status", "cf-request-id"],
                "content": ["checking your browser", "cf-browser-verification",
                           "cf-challenge-running", "please wait while we are checking"],
                "status_codes": [503, 429],
                "risk_weight": 3
            },
            "akamai": {
                "headers": ["x-akamai-transformed", "x-akamai-request-id"],
                "content": ["akamai bot manager", "access denied"],
                "status_codes": [403],
                "risk_weight": 2
            },
            "imperva": {
                "headers": ["x-iinfo", "x-incap-sess-cookie-hdr"],
                "content": ["incapsula", "blocked because of suspicious activity"],
                "status_codes": [403, 503],
                "risk_weight": 3
            },
            "sucuri": {
                "headers": ["x-sucuri-id", "x-sucuri-cache"],
                "content": ["sucuri web firewall", "access denied"],
                "status_codes": [403],
                "risk_weight": 2
            },
            "mod_security": {
                "headers": [],
                "content": ["mod_security", "not acceptable"],
                "status_codes": [406, 501],
                "risk_weight": 1
            },
            "wordfence": {
                "headers": [],
                "content": ["wordfence", "generated by wordfence"],
                "status_codes": [403],
                "risk_weight": 2
            }
        }

        # Bot detection indicators
        self.bot_detection_patterns = {
            "captcha": {
                "content": ["captcha", "recaptcha", "hcaptcha", "verify you are human",
                           "prove you are not a robot", "security check"],
                "risk_weight": 4
            },
            "honeypot": {
                "selectors": [".honeypot", "#honeypot", "[name='honeypot']"],
                "risk_weight": 3
            },
            "behavioral": {
                "content": ["suspicious activity", "unusual traffic", "automated requests"],
                "risk_weight": 2
            },
            "rate_limit": {
                "headers": ["x-ratelimit", "x-rate-limit", "retry-after"],
                "content": ["rate limit", "too many requests", "slow down"],
                "status_codes": [429],
                "risk_weight": 3
            },
            "javascript_protection": {
                "content": ["javascript required", "enable javascript", "noscript"],
                "risk_weight": 2
            }
        }

        # Anti-scraping measures
        self.anti_scraping_indicators = {
            "dynamic_content": {
                "content": ["react", "vue", "angular", "webpack", "babel"],
                "risk_weight": 2
            },
            "session_tracking": {
                "headers": ["set-cookie", "x-session-id"],
                "risk_weight": 1
            },
            "request_fingerprinting": {
                "headers": ["accept-ch", "sec-ch-ua", "sec-ch-ua-mobile"],
                "risk_weight": 1
            },
            "obfuscation": {
                "content": ["eval(", "function(", "var _0x", "webpackJsonp"],
                "risk_weight": 2
            }
        }

        # Risk thresholds
        self.high_risk_threshold = 5
        self.critical_risk_threshold = 8

        # Monitoring state
        self.protection_history = {}
        self.history_window = 10

    async def probe(self, target: Dict[str, Any]) -> SentinelReport:
        """
        Probe target websites for WAF and anti-scraping protections.

        Args:
            target: Target information containing URLs to analyze

        Returns:
            SentinelReport with protection assessment and recommendations
        """
        try:
            urls = self._extract_urls(target)

            if not urls:
                return SentinelReport(
                    sentinel_name=self.name,
                    domain="waf",
                    timestamp=datetime.utcnow(),
                    risk_level="low",
                    findings={"status": "no_urls_provided"},
                    recommended_action="allow"
                )

            # Analyze each URL for protections
            protection_analysis = []
            total_risk_score = 0

            for url in urls[:3]:  # Limit to 3 URLs for performance
                analysis = await self._analyze_url_protections(url)
                protection_analysis.append(analysis)
                total_risk_score += analysis.get("risk_score", 0)

            # Aggregate findings
            all_findings = self._aggregate_findings(protection_analysis)

            # Track protection history
            for url in urls:
                domain = self._extract_domain(url)
                if domain not in self.protection_history:
                    self.protection_history[domain] = []
                self.protection_history[domain].append({
                    "timestamp": datetime.utcnow(),
                    "risk_score": total_risk_score,
                    "protections": all_findings
                })

                # Keep only recent history
                if len(self.protection_history[domain]) > self.history_window:
                    self.protection_history[domain] = self.protection_history[domain][-self.history_window:]

            findings = {
                "urls_analyzed": len(urls),
                "total_risk_score": total_risk_score,
                "protection_analysis": protection_analysis,
                "detected_protections": all_findings,
                "protection_history": self.protection_history
            }

            # Determine risk level and recommended action
            if total_risk_score >= self.critical_risk_threshold:
                risk_level = "critical"
                recommended_action = "block"
            elif total_risk_score >= self.high_risk_threshold:
                risk_level = "high"
                recommended_action = "restrict"
            elif total_risk_score >= 2:
                risk_level = "medium"
                recommended_action = "delay"
            else:
                risk_level = "low"
                recommended_action = "allow"

            return SentinelReport(
                sentinel_name=self.name,
                domain="waf",
                timestamp=datetime.utcnow(),
                risk_level=risk_level,
                findings=findings,
                recommended_action=recommended_action
            )

        except Exception as e:
            logger.error(f"WAF probe failed: {e}")
            return SentinelReport(
                sentinel_name=self.name,
                domain="waf",
                timestamp=datetime.utcnow(),
                risk_level="critical",
                findings={"error": str(e), "error_type": type(e).__name__},
                recommended_action="block"
            )

    def _extract_urls(self, target: Dict[str, Any]) -> List[str]:
        """Extract URLs from target information."""
        urls = []

        # Extract direct URLs
        direct_urls = target.get("urls", [])
        if isinstance(direct_urls, str):
            direct_urls = [direct_urls]
        urls.extend(direct_urls)

        # Extract from single URL field
        single_url = target.get("url")
        if single_url:
            urls.append(single_url)

        # Extract from scraping targets
        targets = target.get("targets", [])
        for t in targets:
            if isinstance(t, str) and (t.startswith("http://") or t.startswith("https://")):
                urls.append(t)
            elif isinstance(t, dict) and "url" in t:
                urls.append(t["url"])

        # Remove duplicates and validate URLs
        valid_urls = []
        seen = set()
        for url in urls:
            if url and url not in seen:
                if url.startswith(("http://", "https://")):
                    valid_urls.append(url)
                    seen.add(url)

        return valid_urls[:5]  # Limit to 5 URLs for performance

    def _extract_domain(self, url: str) -> str:
        """Extract domain from URL."""
        try:
            parsed = urlparse(url)
            return parsed.netloc
        except Exception:
            return url

    async def _analyze_url_protections(self, url: str) -> Dict[str, Any]:
        """Analyze a single URL for WAF and anti-scraping protections."""
        analysis = {
            "url": url,
            "domain": self._extract_domain(url),
            "waf_detected": [],
            "bot_detection": [],
            "anti_scraping": [],
            "risk_score": 0,
            "response_info": {}
        }

        try:
            if not AIOHTTP_AVAILABLE:
                analysis["error"] = "aiohttp not available"
                return analysis

            timeout = aiohttp.ClientTimeout(total=15, connect=10)
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }

            async with aiohttp.ClientSession(timeout=timeout, headers=headers) as session:
                async with session.get(url) as response:
                    analysis["response_info"] = {
                        "status_code": response.status,
                        "headers": dict(response.headers),
                        "content_type": response.headers.get("content-type", "")
                    }

                    # Analyze response headers for WAF signatures
                    headers_text = "\n".join(f"{k}: {v}" for k, v in response.headers.items()).lower()
                    analysis["waf_detected"] = self._detect_waf(headers_text, response.status)

                    # Get response content for content analysis
                    try:
                        content = await response.text()
                        content_lower = content.lower()

                        # Analyze content for WAF and protections
                        analysis["bot_detection"] = self._detect_bot_protections(content_lower, headers_text, response.status)
                        analysis["anti_scraping"] = self._detect_anti_scraping(content_lower, headers_text)

                    except Exception as e:
                        analysis["content_error"] = str(e)

        except asyncio.TimeoutError:
            analysis["error"] = "request_timeout"
            analysis["risk_score"] += 2
        except aiohttp.ClientError as e:
            analysis["error"] = f"client_error: {str(e)}"
            analysis["risk_score"] += 1
        except Exception as e:
            analysis["error"] = f"analysis_error: {str(e)}"
            analysis["risk_score"] += 1

        # Calculate total risk score
        analysis["risk_score"] += sum(p.get("risk_weight", 0) for p in analysis["waf_detected"])
        analysis["risk_score"] += sum(p.get("risk_weight", 0) for p in analysis["bot_detection"])
        analysis["risk_score"] += sum(p.get("risk_weight", 0) for p in analysis["anti_scraping"])

        return analysis

    def _detect_waf(self, headers_text: str, status_code: int) -> List[Dict[str, Any]]:
        """Detect WAF systems from headers and status codes."""
        detected = []

        for waf_name, signatures in self.waf_signatures.items():
            matches = []

            # Check headers
            for header in signatures["headers"]:
                if header.lower() in headers_text:
                    matches.append(f"header:{header}")

            # Check status codes
            if status_code in signatures.get("status_codes", []):
                matches.append(f"status:{status_code}")

            if matches:
                detected.append({
                    "waf": waf_name,
                    "matches": matches,
                    "risk_weight": signatures["risk_weight"]
                })

        return detected

    def _detect_bot_protections(self, content: str, headers_text: str, status_code: int) -> List[Dict[str, Any]]:
        """Detect bot detection and protection mechanisms."""
        detected = []

        for protection_type, patterns in self.bot_detection_patterns.items():
            matches = []

            # Check content patterns
            for pattern in patterns.get("content", []):
                if pattern.lower() in content:
                    matches.append(f"content:{pattern}")

            # Check headers
            for header in patterns.get("headers", []):
                if header.lower() in headers_text:
                    matches.append(f"header:{header}")

            # Check status codes
            if status_code in patterns.get("status_codes", []):
                matches.append(f"status:{status_code}")

            if matches:
                detected.append({
                    "type": protection_type,
                    "matches": matches,
                    "risk_weight": patterns["risk_weight"]
                })

        return detected

    def _detect_anti_scraping(self, content: str, headers_text: str) -> List[Dict[str, Any]]:
        """Detect anti-scraping measures."""
        detected = []

        for measure_type, patterns in self.anti_scraping_indicators.items():
            matches = []

            # Check content patterns
            for pattern in patterns.get("content", []):
                if pattern.lower() in content:
                    matches.append(f"content:{pattern}")

            # Check headers
            for header in patterns.get("headers", []):
                if header.lower() in headers_text:
                    matches.append(f"header:{header}")

            if matches:
                detected.append({
                    "type": measure_type,
                    "matches": matches,
                    "risk_weight": patterns["risk_weight"]
                })

        return detected

    def _aggregate_findings(self, analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Aggregate findings across multiple URL analyses."""
        aggregated = {
            "waf_systems": set(),
            "bot_protections": set(),
            "anti_scraping_measures": set(),
            "total_risk_score": 0,
            "urls_with_protections": 0
        }

        for analysis in analyses:
            if analysis.get("risk_score", 0) > 0:
                aggregated["urls_with_protections"] += 1

            aggregated["total_risk_score"] += analysis.get("risk_score", 0)

            # Aggregate WAF detections
            for waf in analysis.get("waf_detected", []):
                aggregated["waf_systems"].add(waf["waf"])

            # Aggregate bot detections
            for bot in analysis.get("bot_detection", []):
                aggregated["bot_protections"].add(bot["type"])

            # Aggregate anti-scraping measures
            for measure in analysis.get("anti_scraping", []):
                aggregated["anti_scraping_measures"].add(measure["type"])

        # Convert sets to lists for JSON serialization
        aggregated["waf_systems"] = list(aggregated["waf_systems"])
        aggregated["bot_protections"] = list(aggregated["bot_protections"])
        aggregated["anti_scraping_measures"] = list(aggregated["anti_scraping_measures"])

        return aggregated

    def update_risk_thresholds(self, high_threshold: int = None, critical_threshold: int = None) -> None:
        """Update risk assessment thresholds."""
        if high_threshold is not None:
            self.high_risk_threshold = high_threshold
        if critical_threshold is not None:
            self.critical_risk_threshold = critical_threshold

        logger.info(f"Updated WAF risk thresholds: high={self.high_risk_threshold}, critical={self.critical_risk_threshold}")

    def add_custom_waf_signature(self, name: str, headers: List[str] = None,
                               content: List[str] = None, status_codes: List[int] = None,
                               risk_weight: int = 1) -> None:
        """Add custom WAF signature for detection."""
        self.waf_signatures[name.lower()] = {
            "headers": headers or [],
            "content": content or [],
            "status_codes": status_codes or [],
            "risk_weight": risk_weight
        }

        logger.info(f"Added custom WAF signature: {name}")

    def get_protection_history(self, domain: str = None) -> Dict[str, Any]:
        """Get protection detection history."""
        if domain:
            return {domain: self.protection_history.get(domain, [])}
        return self.protection_history.copy()


# Factory function for easy instantiation
def create_waf_sentinel(high_risk_threshold: int = 5, critical_risk_threshold: int = 8) -> WafSentinel:
    """
    Create a WAF sentinel with sensible defaults.

    Args:
        high_risk_threshold: Risk score threshold for high risk
        critical_risk_threshold: Risk score threshold for critical risk

    Returns:
        Configured WafSentinel instance
    """
    sentinel = WafSentinel()
    sentinel.update_risk_thresholds(
        high_threshold=high_risk_threshold,
        critical_threshold=critical_risk_threshold
    )

    return sentinel
