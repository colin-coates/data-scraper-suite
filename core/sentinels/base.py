# Copyright (c) 2024 Mountain Jewels Intelligence. All rights reserved.
#
# This software is proprietary and confidential. Unauthorized copying,
# modification, distribution, or use is strictly prohibited.

"""
Sentinel Base Classes for MJ Data Scraper Suite

Provides monitoring, alerting, and automated response systems for scraping operations.
Sentinels probe targets and return structured reports with risk assessments and recommendations.
"""

import asyncio
import logging
import time
from abc import ABC, abstractmethod
from datetime import datetime
from enum import Enum
from typing import Dict, Any, Optional
from collections import defaultdict, deque

try:
    from pydantic import BaseModel
except ImportError:
    # Fallback for environments without pydantic
    class BaseModel:
        def __init__(self, **data):
            for key, value in data.items():
                setattr(self, key, value)

        def dict(self):
            return self.__dict__

from ..scrape_telemetry import get_global_telemetry_collector

logger = logging.getLogger(__name__)


class SentinelReport(BaseModel):
    """Structured report from sentinel probe operations."""
    sentinel_name: str
    domain: str  # e.g., "performance", "security", "compliance", "network"
    timestamp: datetime
    risk_level: str  # "low" | "medium" | "high" | "critical"
    findings: Dict[str, Any]
    recommended_action: str  # "allow" | "restrict" | "delay" | "block"


class BaseSentinel(ABC):
    """Base class for all sentinels in the MJ Data Scraper Suite."""

    name: str

    @abstractmethod
    async def probe(self, target: Dict[str, Any]) -> SentinelReport:
        """
        Probe a target and return a structured sentinel report.

        Args:
            target: Target information to probe (URL, domain, operation context, etc.)

        Returns:
            SentinelReport with findings, risk assessment, and recommendations
        """
        pass

    async def probe_with_fallback(self, target: Dict[str, Any]) -> SentinelReport:
        """
        Probe with error handling and fallback reporting.

        Args:
            target: Target information to probe

        Returns:
            SentinelReport, with error details if probing fails
        """
        try:
            return await self.probe(target)
        except Exception as e:
            logger.error(f"Sentinel {self.name} probe failed for target {target}: {e}")
            return SentinelReport(
                sentinel_name=self.name,
                domain="error",
                timestamp=datetime.utcnow(),
                risk_level="critical",
                findings={"error": str(e), "target": target},
                recommended_action="block"
            )

    def get_sentinel_info(self) -> Dict[str, Any]:
        """Get basic information about this sentinel."""
        return {
            "name": self.name,
            "type": self.__class__.__name__,
            "module": self.__class__.__module__
        }


class SentinelSeverity:
    """Severity levels for sentinel alerts."""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class SentinelStatus(Enum):
    """Status of sentinel monitoring."""
    ACTIVE = "active"
    INACTIVE = "inactive"
    ALERTING = "alerting"
    MAINTENANCE = "maintenance"


class SentinelAlert:
    """Alert generated by a sentinel."""
    def __init__(self, sentinel_name: str, severity: SentinelSeverity, message: str,
                 details: Optional[Dict[str, Any]] = None, timestamp: Optional[datetime] = None,
                 resolved: bool = False, resolved_at: Optional[datetime] = None,
                 alert_id: Optional[str] = None):
        self.sentinel_name = sentinel_name
        self.severity = severity
        self.message = message
        self.details = details or {}
        self.timestamp = timestamp or datetime.utcnow()
        self.resolved = resolved
        self.resolved_at = resolved_at
        self.alert_id = alert_id or f"alert_{int(time.time() * 1000)}"

    def resolve(self) -> None:
        """Mark the alert as resolved."""
        self.resolved = True
        self.resolved_at = datetime.utcnow()
        logger.info(f"Alert {self.alert_id} resolved: {self.message}")

    def to_dict(self) -> Dict[str, Any]:
        """Convert alert to dictionary."""
        return {
            "alert_id": self.alert_id,
            "sentinel_name": self.sentinel_name,
            "severity": self.severity.value,
            "message": self.message,
            "details": self.details,
            "timestamp": self.timestamp.isoformat(),
            "resolved": self.resolved,
            "resolved_at": self.resolved_at.isoformat() if self.resolved_at else None
        }


class SentinelConfig:
    """Configuration for sentinel instances."""
    def __init__(self, name: str, enabled: bool = True, check_interval: float = 60.0,
                 alert_threshold: int = 3, cooldown_period: float = 300.0,
                 severity: SentinelSeverity = SentinelSeverity.WARNING,
                 auto_resolve: bool = True, alert_channels: Optional[list] = None):
        self.name = name
        self.enabled = enabled
        self.check_interval = check_interval
        self.alert_threshold = alert_threshold
        self.cooldown_period = cooldown_period
        self.severity = severity
        self.auto_resolve = auto_resolve
        self.alert_channels = alert_channels or ["log"]

    def validate(self) -> None:
        """Validate sentinel configuration."""
        if self.check_interval <= 0:
            raise ValueError("check_interval must be positive")
        if self.alert_threshold < 1:
            raise ValueError("alert_threshold must be at least 1")
        if self.cooldown_period < 0:
            raise ValueError("cooldown_period cannot be negative")


class SentinelRunner:
    """
    Runner for sentinel probes with monitoring and alerting capabilities.

    Wraps BaseSentinel instances to provide monitoring infrastructure,
    alert generation, and automated response handling.
    """

    def __init__(self, sentinel: BaseSentinel, config: Optional[SentinelConfig] = None):
        self.sentinel = sentinel
        self.config = config or SentinelConfig(name=f"{sentinel.name}_runner")

        self.status = SentinelStatus.ACTIVE
        self.last_check_time = 0.0
        self.consecutive_failures = 0
        self.last_alert_time = 0.0
        self.active_alerts: List[SentinelAlert] = []
        self.alert_history: deque[SentinelAlert] = deque(maxlen=1000)
        self.last_report: Optional[SentinelReport] = None

        # Callbacks
        self.on_alert: Optional[Callable[[SentinelAlert], None]] = None
        self.on_resolve: Optional[Callable[[SentinelAlert], None]] = None
        self.on_status_change: Optional[Callable[[SentinelStatus, SentinelStatus], None]] = None
        self.on_report: Optional[Callable[[SentinelReport], None]] = None

        # Telemetry integration
        self.telemetry_collector = get_global_telemetry_collector()

        logger.info(f"SentinelRunner for {sentinel.name} initialized")

    async def probe_target(self, target: Dict[str, Any]) -> SentinelReport:
        """
        Execute a probe and handle the results.

        Args:
            target: Target to probe

        Returns:
            SentinelReport from the probe
        """
        report = await self.sentinel.probe_with_fallback(target)
        self.last_report = report

        # Handle report based on risk level and recommended action
        await self._handle_report(report, target)

        # Call report callback
        if self.on_report:
            try:
                self.on_report(report)
            except Exception as e:
                logger.error(f"Report callback failed for {self.sentinel.name}: {e}")

        return report

    async def _handle_report(self, report: SentinelReport, target: Dict[str, Any]):
        """Handle sentinel report and take appropriate actions."""
        # Check if this constitutes an alert condition
        should_alert = self._should_alert_on_report(report)

        if should_alert:
            await self._generate_report_alert(report, target)
        else:
            # Clear any existing alerts if risk is now acceptable
            if self.active_alerts and report.risk_level in ["low", "medium"]:
                await self._resolve_active_alerts()

    def _should_alert_on_report(self, report: SentinelReport) -> bool:
        """Determine if a report should trigger an alert."""
        # Alert on high-risk or critical findings
        if report.risk_level in ["high", "critical"]:
            return True

        # Alert on restrictive recommendations
        if report.recommended_action in ["restrict", "delay", "block"]:
            return True

        # Could add more sophisticated logic here
        return False

    async def _generate_report_alert(self, report: SentinelReport, target: Dict[str, Any]):
        """Generate an alert based on sentinel report."""
        # Map risk level to severity
        severity_map = {
            "low": SentinelSeverity.INFO,
            "medium": SentinelSeverity.WARNING,
            "high": SentinelSeverity.ERROR,
            "critical": SentinelSeverity.CRITICAL
        }

        severity = severity_map.get(report.risk_level, SentinelSeverity.WARNING)

        alert = SentinelAlert(
            sentinel_name=self.sentinel.name,
            severity=severity,
            message=f"Risk assessment: {report.risk_level} - {report.recommended_action}",
            details={
                "report": report.dict(),
                "target": target,
                "domain": report.domain
            }
        )

        self.active_alerts.append(alert)
        self.alert_history.append(alert)

        # Update status if this is our first active alert
        if len(self.active_alerts) == 1:
            await self._change_status(SentinelStatus.ALERTING)

        # Call alert callback
        if self.on_alert:
            try:
                self.on_alert(alert)
            except Exception as e:
                logger.error(f"Alert callback failed for {self.sentinel.name}: {e}")

        # Send alert to configured channels
        await self._send_alert_to_channels(alert)

        logger.warning(f"Sentinel {self.sentinel.name} generated {alert.severity.value} alert: {alert.message}")

    async def _resolve_active_alerts(self):
        """Resolve all active alerts."""
        resolved_alerts = []
        for alert in self.active_alerts:
            if not alert.resolved:
                alert.resolve()
                resolved_alerts.append(alert)

                if self.on_resolve:
                    try:
                        self.on_resolve(alert)
                    except Exception as e:
                        logger.error(f"Resolve callback failed for {self.sentinel.name}: {e}")

        self.active_alerts.clear()

        if resolved_alerts and self.status == SentinelStatus.ALERTING:
            await self._change_status(SentinelStatus.ACTIVE)

        if resolved_alerts:
            logger.info(f"Sentinel {self.sentinel.name} resolved {len(resolved_alerts)} alerts")

    async def _change_status(self, new_status: SentinelStatus):
        """Change sentinel status and notify callbacks."""
        old_status = self.status
        self.status = new_status

        if self.on_status_change and old_status != new_status:
            try:
                self.on_status_change(old_status, new_status)
            except Exception as e:
                logger.error(f"Status change callback failed for {self.sentinel.name}: {e}")

        logger.info(f"Sentinel {self.sentinel.name} status changed: {old_status.value} -> {new_status.value}")

    async def _send_alert_to_channels(self, alert: SentinelAlert):
        """Send alert to configured channels."""
        for channel in self.config.alert_channels:
            try:
                if channel == "log":
                    # Already logged above
                    pass
                elif channel == "email":
                    await self._send_email_alert(alert)
                elif channel == "slack":
                    await self._send_slack_alert(alert)
                elif channel == "webhook":
                    await self._send_webhook_alert(alert)
                else:
                    logger.warning(f"Unknown alert channel: {channel}")
            except Exception as e:
                logger.error(f"Failed to send alert to {channel}: {e}")

    async def _send_email_alert(self, alert: SentinelAlert):
        """Send alert via email."""
        logger.debug(f"Would send email alert: {alert.message}")

    async def _send_slack_alert(self, alert: SentinelAlert):
        """Send alert via Slack."""
        logger.debug(f"Would send Slack alert: {alert.message}")

    async def _send_webhook_alert(self, alert: SentinelAlert):
        """Send alert via webhook."""
        logger.debug(f"Would send webhook alert: {alert.message}")

    def get_metrics(self) -> Dict[str, Any]:
        """Get sentinel runner metrics."""
        return {
            "sentinel_name": self.sentinel.name,
            "sentinel_type": self.sentinel.__class__.__name__,
            "status": self.status.value,
            "active_alerts": len(self.active_alerts),
            "total_alerts": len(self.alert_history),
            "last_check_time": self.last_check_time,
            "last_alert_time": self.last_alert_time,
            "last_report": self.last_report.dict() if self.last_report else None
        }

    def get_active_alerts(self) -> List[SentinelAlert]:
        """Get list of currently active alerts."""
        return self.active_alerts.copy()

    def get_last_report(self) -> Optional[SentinelReport]:
        """Get the last sentinel report."""
        return self.last_report

    async def execute_check(self) -> None:
        """
        Execute a single check cycle.

        This method handles the check execution, alert generation, and state management.
        """
        if self.status != SentinelStatus.ACTIVE:
            return

        try:
            current_time = time.time()

            # Check if it's time for another check
            if current_time - self.last_check_time < self.config.check_interval:
                return

            self.last_check_time = current_time

            # Execute the specific condition check
            is_healthy, message, details = await self.check_condition()

            if is_healthy:
                # Reset consecutive failures on success
                if self.consecutive_failures > 0:
                    logger.info(f"Sentinel {self.config.name} recovered: {message}")
                    await self._resolve_active_alerts()
                self.consecutive_failures = 0
            else:
                # Increment consecutive failures
                self.consecutive_failures += 1
                logger.warning(f"Sentinel {self.config.name} condition failed ({self.consecutive_failures}/{self.config.alert_threshold}): {message}")

                # Check if we should alert
                if (self.consecutive_failures >= self.config.alert_threshold and
                    current_time - self.last_alert_time >= self.config.cooldown_period):
                    await self._generate_alert(message, details)
                    self.last_alert_time = current_time

        except Exception as e:
            logger.error(f"Sentinel {self.config.name} check failed with exception: {e}")
            self.consecutive_failures += 1

            if self.consecutive_failures >= self.config.alert_threshold:
                await self._generate_alert(f"Check execution failed: {str(e)}", {"exception": str(e)})

    async def _generate_alert(self, message: str, details: Dict[str, Any]) -> None:
        """Generate and handle a new alert."""
        alert = SentinelAlert(
            sentinel_name=self.config.name,
            severity=self.config.severity,
            message=message,
            details=details
        )

        self.active_alerts.append(alert)
        self.alert_history.append(alert)

        # Update status if this is our first active alert
        if len(self.active_alerts) == 1:
            await self._change_status(SentinelStatus.ALERTING)

        # Call alert callback
        if self.on_alert:
            try:
                self.on_alert(alert)
            except Exception as e:
                logger.error(f"Alert callback failed for {self.config.name}: {e}")

        # Send alert to configured channels
        await self._send_alert_to_channels(alert)

        logger.warning(f"Sentinel {self.config.name} generated {alert.severity.value} alert: {alert.message}")

    async def _resolve_active_alerts(self) -> None:
        """Resolve all active alerts if auto-resolve is enabled."""
        if not self.config.auto_resolve:
            return

        resolved_alerts = []
        for alert in self.active_alerts:
            if not alert.resolved:
                alert.resolve()
                resolved_alerts.append(alert)

                if self.on_resolve:
                    try:
                        self.on_resolve(alert)
                    except Exception as e:
                        logger.error(f"Resolve callback failed for {self.config.name}: {e}")

        self.active_alerts.clear()

        if resolved_alerts and self.status == SentinelStatus.ALERTING:
            await self._change_status(SentinelStatus.ACTIVE)

        if resolved_alerts:
            logger.info(f"Sentinel {self.config.name} resolved {len(resolved_alerts)} alerts")

    async def _change_status(self, new_status: SentinelStatus) -> None:
        """Change sentinel status and notify callbacks."""
        old_status = self.status
        self.status = new_status

        if self.on_status_change and old_status != new_status:
            try:
                self.on_status_change(old_status, new_status)
            except Exception as e:
                logger.error(f"Status change callback failed for {self.config.name}: {e}")

        logger.info(f"Sentinel {self.config.name} status changed: {old_status.value} -> {new_status.value}")

    async def _send_alert_to_channels(self, alert: SentinelAlert) -> None:
        """Send alert to configured channels."""
        for channel in self.config.alert_channels:
            try:
                if channel == "log":
                    # Already logged above
                    pass
                elif channel == "email":
                    await self._send_email_alert(alert)
                elif channel == "slack":
                    await self._send_slack_alert(alert)
                elif channel == "webhook":
                    await self._send_webhook_alert(alert)
                else:
                    logger.warning(f"Unknown alert channel: {channel}")
            except Exception as e:
                logger.error(f"Failed to send alert to {channel}: {e}")

    async def _send_email_alert(self, alert: SentinelAlert) -> None:
        """Send alert via email (placeholder for implementation)."""
        # TODO: Implement email integration
        logger.debug(f"Would send email alert: {alert.message}")

    async def _send_slack_alert(self, alert: SentinelAlert) -> None:
        """Send alert via Slack (placeholder for implementation)."""
        # TODO: Implement Slack integration
        logger.debug(f"Would send Slack alert: {alert.message}")

    async def _send_webhook_alert(self, alert: SentinelAlert) -> None:
        """Send alert via webhook (placeholder for implementation)."""
        # TODO: Implement webhook integration
        logger.debug(f"Would send webhook alert: {alert.message}")

    def get_metrics(self) -> Dict[str, Any]:
        """Get sentinel performance metrics."""
        return {
            "sentinel_name": self.config.name,
            "sentinel_type": self.__class__.__name__,
            "status": self.status.value,
            "check_interval": self.config.check_interval,
            "consecutive_failures": self.consecutive_failures,
            "active_alerts": len(self.active_alerts),
            "total_alerts": len(self.alert_history),
            "last_check_time": self.last_check_time,
            "last_alert_time": self.last_alert_time,
            "severity": self.config.severity
        }

    def get_active_alerts(self) -> List[SentinelAlert]:
        """Get list of currently active alerts."""
        return self.active_alerts.copy()

    def get_alert_history(self, limit: Optional[int] = None) -> List[SentinelAlert]:
        """Get alert history, optionally limited to most recent."""
        alerts = list(self.alert_history)
        if limit:
            alerts = alerts[-limit:]
        return alerts

    def reset_metrics(self) -> None:
        """Reset sentinel metrics (useful for testing)."""
        self.consecutive_failures = 0
        self.last_alert_time = 0.0
        self.active_alerts.clear()
        logger.info(f"Metrics reset for sentinel {self.config.name}")

    async def start_monitoring(self) -> None:
        """Start the sentinel monitoring loop."""
        self.status = SentinelStatus.ACTIVE
        logger.info(f"Started monitoring for sentinel {self.config.name}")

        while self.status == SentinelStatus.ACTIVE:
            try:
                await self.execute_check()
                await asyncio.sleep(min(self.config.check_interval, 1.0))  # Don't sleep too long
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Monitoring loop error for {self.config.name}: {e}")
                await asyncio.sleep(5.0)  # Brief pause on error

        logger.info(f"Stopped monitoring for sentinel {self.config.name}")

    def stop_monitoring(self) -> None:
        """Stop the sentinel monitoring."""
        self.status = SentinelStatus.INACTIVE
        logger.info(f"Monitoring stopped for sentinel {self.config.name}")

    def set_maintenance_mode(self) -> None:
        """Put sentinel in maintenance mode (suppresses alerts)."""
        self.status = SentinelStatus.MAINTENANCE
        logger.info(f"Maintenance mode enabled for sentinel {self.config.name}")

    def __str__(self) -> str:
        return f"{self.__class__.__name__}(name={self.config.name}, status={self.status.value}, alerts={len(self.active_alerts)})"


# Global sentinel registry
_sentinel_registry: Dict[str, SentinelBase] = {}


def register_sentinel(sentinel: SentinelBase) -> None:
    """Register a sentinel in the global registry."""
    _sentinel_registry[sentinel.config.name] = sentinel
    logger.info(f"Registered sentinel: {sentinel.config.name}")


def unregister_sentinel(name: str) -> None:
    """Unregister a sentinel from the global registry."""
    if name in _sentinel_registry:
        del _sentinel_registry[name]
        logger.info(f"Unregistered sentinel: {name}")


def get_registered_sentinels() -> Dict[str, SentinelBase]:
    """Get all registered sentinels."""
    return _sentinel_registry.copy()


def get_sentinel(name: str) -> Optional[SentinelBase]:
    """Get a specific registered sentinel by name."""
    return _sentinel_registry.get(name)


async def start_all_sentinels() -> None:
    """Start monitoring for all registered sentinels."""
    tasks = []
    for sentinel in _sentinel_registry.values():
        if sentinel.config.enabled:
            task = asyncio.create_task(sentinel.start_monitoring())
            tasks.append(task)

    if tasks:
        logger.info(f"Started monitoring for {len(tasks)} sentinels")
        await asyncio.gather(*tasks, return_exceptions=True)
    else:
        logger.info("No sentinels to start")


def stop_all_sentinels() -> None:
    """Stop monitoring for all registered sentinels."""
    for sentinel in _sentinel_registry.values():
        sentinel.stop_monitoring()
    logger.info("Stopped all sentinels")
